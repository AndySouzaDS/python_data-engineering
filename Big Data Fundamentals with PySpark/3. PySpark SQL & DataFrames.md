## # Abstracting Data with DataFrames
### # create df from RDD
```py
iphones_R00 sc.parallelize ([
  (XS, 2018, 5.65, 2.79, 6.24),
  (XR", 2018, 5.94, 2.98, 6.84),
  (X10, 2017, 5.65, 2.79, 6.13),
  (8PLUS, 2017, 6.23, 3.07, 7.12)
])

names ["Model", "Year", "Height", "Width", "Weight"]

iphones_df = spark.createDataFrame (iphones_RDD, schema=names)
type(iphones_df)
```
    pyspark. sql.dataframe . DataFrame
### # Create a DataFrame from reading a CSV/JSON/TXT
```py
df_csv spark. read.csv("people. csv", header=True , inferSchema=True)
df_json spark.read.json("people . json", header=True, inferSchema=True)
df txt= spark. read. txt("people. txt", header=True, inferSchema= True)
```
- Path to the file and two optional parameters
- Two optional parameters
  `header=True, inferSchema=True`
## RDD to DataFrame
Instructions
- [x] Create an RDD from the sample_list.
- [x] Create a PySpark DataFrame using the above RDD and schema.
- [x] Confirm the output as PySpark DataFrame.
```py

```
