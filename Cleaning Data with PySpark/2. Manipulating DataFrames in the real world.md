## # DataFrame column operations
### # example
```py
#Return rows where name starts with "M"
voter df. filter (voter_df.name.like ( M%*))

#Return name and position only
voters voter_df. select (' name", 'position ')
```
### # Common DataFrame transformations
negate with `~`
```py
# Filter/Where
voter_df.filter (voter_df.date > '1/1/2019') # or voter_df.where ( . . .)

# Select
Voter_df.select(voter_df.name)

# withColumn
voter_df.withColumn ('year', voter_df.date.year)

# drop
voter_df.drop("unused_colLumn")
```
### # Column string transformations
- Contained in pyspark.sql.functions
```py
import pyspark. sql. functions as F

# Applied per column as transformation
voter_df. withColumn ( "upper', F.upper (" name " ))

# Can create intermediary columns
voter_df.withColumn ( 'splits', F. split (' name", ))

# Can cast to other types
voter df.withcolumn('year ", voter_df ['_c4'].cast (IntegerType ()))
```
### # ArrayType) column functions
- Various utility functions / transformations to interact with ArrayType0
`.size(<column>)` returns length of arrayType) column
`.getItem(<index>)` used to retrieve a specific item at index of list column.
## Filtering column content with Python
- [x] Show the distinct VOTER_NAME entries.
- [x] Filter voter_df where the VOTER_NAME is 1-20 characters in length.
- [x] Filter out voter_df where the VOTER_NAME contains an _.
- [x] Show the distinct VOTER_NAME entries again.
```py
