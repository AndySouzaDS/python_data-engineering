## # Caching
`call.cache ()` on the DataFrame before Action
```py
voter_df spark.read.csv("voter_data.txt.gz')
voter_df.cache ().count ()

voter_df = voter_df. withColumn ("IDÂ°, monotonically_increasing_id ())
voter_df = voter_df.cache (O
voter_df.show()
```
### # more chache operators
Check `.is_cached` to determine cache status
```py
print (voter_df.is_cached)
```
    True
Call `unpersist ()` when finished with DataFrame
## Caching a DataFrame
- [x] Cache the unique rows in the departures_df DataFrame.
- [x] Perform a count query on departures_df, noting how long the operation takes.
- [x] Count the rows again, noting the variance in time of a cached DataFrame.
```py
